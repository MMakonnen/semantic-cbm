{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIAL MVP ALL IN HERE -> spread into proper files and implement properly\n",
    "\n",
    "- currently only uses: LSTMConceptCorrector\n",
    "- realignment (i.e., intervention updates) happens only within a cluster, more specifically:\n",
    "  A custom “three-state mask” pipeline for concept realignment, with:\n",
    "  0 = open (the LSTM can update/realign this concept),\n",
    "  1 = permanently locked to ground truth (once an intervention happens -> replace by ground truth),\n",
    "  2 = temporarily locked for the current iteration (but reverts to 0 in the next iteration if not permanently locked -> for out of cluster concepts)\n",
    "- for now use synthetic data generation\n",
    "\n",
    "TODO:\n",
    "\n",
    "- get 2nd perspective on code\n",
    "- make sure everything moved to GPU\n",
    "- extend by other models for alignment (GRU and MLP and ...)\n",
    "- spread code properly over multiple files and do not implement in notebook\n",
    "- fit into whole pipeline, i.e. using real data and CBM model\n",
    "- correct all variable and par names and make them in line with proposal/final text\n",
    "\n",
    "MINOR NOTES:\n",
    "\n",
    "- ensure that all clusters and labels have atleast one observation (synthetic data context)\n",
    "\n",
    "GOOD TEXT CHUNKS FOR WRITTING (shorten and cut out certain parts):\n",
    "\n",
    "## Concept Clusters and Implicit Propagation\n",
    "\n",
    "### Concept Clusters\n",
    "\n",
    "In machine learning models, especially in complex domains like medical diagnosis, **concept clusters** are essential. These clusters consist of related or interdependent concepts that collectively represent a broader phenomenon. For example, in diagnosing respiratory infections, concepts such as \"fever,\" \"cough,\" and \"fatigue\" may form a cluster. Clustering helps manage inherent dependencies among concepts, ensuring that interventions on one concept naturally influence others within the same cluster, thereby maintaining consistency and coherence in the model's predictions.\n",
    "\n",
    "### Implicit Propagation via LSTM\n",
    "\n",
    "To capture dependencies within concept clusters, **Long Short-Term Memory (LSTM)** networks are utilized for their ability to model **sequential dependencies** and **temporal patterns**. When an intervention targets a single concept, the LSTM effectively models the intricate relationships within the cluster. During training, intervening on a concept like \"fever\" influences related concepts such as \"cough\" and \"fatigue,\" enabling the LSTM to **implicitly propagate** the intervention's effects across the entire cluster. This fosters a holistic and interconnected understanding of the underlying concepts.\n",
    "\n",
    "## Pipeline Mechanism for Implicit Propagation\n",
    "\n",
    "### Intervention on Individual Concepts\n",
    "\n",
    "Central to the pipeline is the **intervene function**, which selects and applies interventions on individual concepts based on an **uncertainty-based policy**. For each sample in a batch, the function identifies the most critical concept—determined by its uncertainty—and sets it to its ground truth value, marking it as **permanently locked** (`mask=1`). Additionally, all other concepts within the same cluster are **temporarily locked** (`mask=2`) to prevent unintended modifications during the current intervention round. This targeted intervention provides a clear ground truth signal for the model to correct its predictions. Consequently, the LSTM observes these corrections and learns to adjust related concepts within the same cluster **implicitly**, enhancing the model's ability to refine its predictions systematically.\n",
    "\n",
    "### LSTM Concept Corrector\n",
    "\n",
    "The **LSTMConceptCorrector** is responsible for realigning and correcting concept vectors based on interventions. It processes sequences of concept vectors, capturing the **temporal evolution** of corrections across multiple intervention steps. The model inputs a combination of **locked** (intervened) and **open** (modifiable) concepts. Locked concepts remain unchanged, while open concepts are adjusted based on the LSTM's learned patterns. Temporarily locked concepts are held steady during the current intervention round but are reset to open (`mask=0`) after realignment, allowing for future interventions if necessary. Through successive intervention and correction cycles, the LSTM learns the dependencies within concept clusters, effectively modeling how changes in one concept influence others within the same group. This dynamic adjustment ensures coherence and accuracy in the model's concept representations.\n",
    "\n",
    "### Sample Trajectory Function\n",
    "\n",
    "The **sample trajectory function** simulates the iterative process of interventions and realignments. It orchestrates a sequence of intervention steps, each followed by a realignment phase handled by the LSTMConceptCorrector. By conducting multiple rounds of interventions, the function enables the LSTM to progressively refine its concept predictions based on prior corrections. This iterative approach enhances the model's ability to correct individual concepts and reinforces the **implicit propagation** of interventions across related concepts within clusters. Consequently, the model develops more accurate and interdependent concept representations, closely aligning with the underlying structure of the concept clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST A FEW THINGS TO BE AWARE OF:\n",
    "\n",
    "# B - Batch size\n",
    "# T - Number of time steps\n",
    "# k - number of concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNTHETIC DATA GENERATION\n",
    "\n",
    "\n",
    "def generate_synthetic_data(k, n, J, m, seed):\n",
    "    \"\"\"\n",
    "    k: number of concepts\n",
    "    n: number of observations\n",
    "    J: number of target classes\n",
    "    m: number of concept clusters\n",
    "    seed: random seed\n",
    "\n",
    "    Returns:\n",
    "      predicted_concepts: float in [0,1], shape (n, k)\n",
    "      groundtruth_concepts: binary in {0,1}, shape (n, k)\n",
    "      cluster_assignments: dict {cluster_id: [concept_indices]}\n",
    "      labels: integer class label for each observation in [0..J-1], shape (n,)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # predicted concepts in [0,1]\n",
    "    predicted_concepts = torch.rand(n, k)\n",
    "\n",
    "    # ground truth concepts in {0,1}\n",
    "    groundtruth_concepts = (torch.rand(n, k) > 0.5).float()\n",
    "\n",
    "    # create random cluster assignment\n",
    "    cluster_assignments = {cid: [] for cid in range(m)}\n",
    "    for concept_idx in range(k):\n",
    "        assigned_cluster = torch.randint(low=0, high=m, size=(1,)).item()\n",
    "        cluster_assignments[assigned_cluster].append(concept_idx)\n",
    "\n",
    "    # randomly assign labels in {0,...,J-1}\n",
    "    labels = torch.randint(low=0, high=J, size=(n,))\n",
    "\n",
    "    return predicted_concepts, groundtruth_concepts, cluster_assignments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERVENTION POLICY\n",
    "\n",
    "\n",
    "def ucp(concepts, already_intervened_concepts):\n",
    "    \"\"\"\n",
    "    Uncertainty-based Concept Picking (UCP) policy.\n",
    "\n",
    "    Args:\n",
    "        concepts (torch.Tensor): Current concept values, shape (B, k).\n",
    "        already_intervened_concepts (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "                                                  1 => permanently locked, 0 => open, 2 => temporarily locked.\n",
    "\n",
    "    Returns:\n",
    "        importances (torch.Tensor): Importance scores for each concept, shape (B, k).\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    # Importance inversely proportional to distance from 0.5\n",
    "    importances = 1.0 / (torch.abs(concepts - 0.5) + eps)\n",
    "\n",
    "    # Exclude permanently and temporarily locked concepts by setting their importance to a large negative value\n",
    "    importances[(already_intervened_concepts == 1) | (already_intervened_concepts == 2)] = -1e10\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERVENTION FUNCTION\n",
    "\n",
    "\n",
    "def intervene(concepts, concept_to_cluster, already_intervened_concepts, groundtruth_concepts, \n",
    "             intervention_policy=ucp):\n",
    "    \"\"\"\n",
    "    Applies the intervention policy to select and intervene on individual concepts.\n",
    "\n",
    "    Args:\n",
    "        concepts (torch.Tensor): Current concept values, shape (B, k).\n",
    "        concept_to_cluster (list): List mapping each concept to its cluster, length k.\n",
    "        already_intervened_concepts (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "                                                  1 => permanently locked, 0 => open, 2 => temporarily locked.\n",
    "        groundtruth_concepts (torch.Tensor): Ground truth concept values, shape (B, k).\n",
    "        intervention_policy (function): Function to compute importances.\n",
    "\n",
    "    Returns:\n",
    "        concepts_new (torch.Tensor): Updated concept values after intervention, shape (B, k).\n",
    "        intervened_concepts_new (torch.Tensor): Updated mask, shape (B, k).\n",
    "    \"\"\"\n",
    "    B, k = concepts.shape\n",
    "\n",
    "    # Compute importances using the chosen policy\n",
    "    importances = intervention_policy(concepts, already_intervened_concepts)\n",
    "    \n",
    "    # Select the most important concept to intervene on for each sample\n",
    "    concepts_to_intervene = torch.argmax(importances, dim=1)  # shape: (B,)\n",
    "    \n",
    "    # Replace selected concepts with ground truth values\n",
    "    indices = torch.arange(B, device=concepts.device)\n",
    "    concepts_new = concepts.clone()\n",
    "    concepts_new[indices, concepts_to_intervene] = groundtruth_concepts[indices, concepts_to_intervene]\n",
    "    \n",
    "    # Update the intervention mask to permanently lock the intervened concepts\n",
    "    intervened_concepts_new = already_intervened_concepts.clone()\n",
    "    intervened_concepts_new[indices, concepts_to_intervene] = 1\n",
    "    \n",
    "    # Create a tensor mapping each concept to its cluster\n",
    "    concept_to_cluster_tensor = torch.tensor(concept_to_cluster, device=concepts.device)  # shape: (k,)\n",
    "    \n",
    "    # Get cluster IDs for the selected concepts\n",
    "    selected_clusters = concept_to_cluster_tensor[concepts_to_intervene]  # shape: (B,)\n",
    "    \n",
    "    # Create a mask for each sample indicating which concepts are in the selected cluster\n",
    "    # Shape: (B, k)\n",
    "    cluster_mask = concept_to_cluster_tensor.unsqueeze(0) == selected_clusters.unsqueeze(1)\n",
    "    \n",
    "    # Identify concepts not in the selected cluster\n",
    "    outside_cluster_mask = ~cluster_mask  # Shape: (B, k)\n",
    "    \n",
    "    # Do not overwrite already permanently locked concepts (mask == 1)\n",
    "    temp_lock_outside_cluster = (outside_cluster_mask & (intervened_concepts_new != 1))\n",
    "    \n",
    "    # Set mask to `2` where applicable\n",
    "    intervened_concepts_new = torch.where(temp_lock_outside_cluster, \n",
    "                                         torch.tensor(2, device=concepts.device), \n",
    "                                         intervened_concepts_new)\n",
    "    \n",
    "    return concepts_new, intervened_concepts_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD INTERVENTION FUNCTION (NOT CORRECT BUT LEFT HERE FOR NOW)\n",
    "\n",
    "\n",
    "# def intervene(concepts, concept_to_cluster, already_intervened_concepts, groundtruth_concepts, \n",
    "#              intervention_policy=ucp):\n",
    "#     \"\"\"\n",
    "#     Applies the intervention policy to select and intervene on individual concepts.\n",
    "\n",
    "#     Args:\n",
    "#         concepts (torch.Tensor): Current concept values, shape (B, k).\n",
    "#         concept_to_cluster (list): List mapping each concept to its cluster, length k.\n",
    "#         already_intervened_concepts (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "#                                                   1 => permanently locked, 0 => open, 2 => temporarily locked.\n",
    "#         groundtruth_concepts (torch.Tensor): Ground truth concept values, shape (B, k).\n",
    "#         intervention_policy (function): Function to compute importances.\n",
    "\n",
    "#     Returns:\n",
    "#         concepts_new (torch.Tensor): Updated concept values after intervention, shape (B, k).\n",
    "#         intervened_concepts_new (torch.Tensor): Updated mask, shape (B, k).\n",
    "#     \"\"\"\n",
    "#     # Compute importances using the chosen policy\n",
    "#     importances = intervention_policy(concepts, already_intervened_concepts)\n",
    "    \n",
    "#     B, k = concepts.shape\n",
    "\n",
    "#     # Select the most important concept to intervene on for each sample\n",
    "#     concepts_to_intervene = torch.argmax(importances, dim=1)  # shape: (B,)\n",
    "\n",
    "#     # Replace selected concepts with ground truth values\n",
    "#     concepts_new = concepts.clone()\n",
    "#     concepts_new[range(B), concepts_to_intervene] = groundtruth_concepts[range(B), concepts_to_intervene]\n",
    "\n",
    "#     # Update the intervention mask to permanently lock the intervened concepts\n",
    "#     intervened_concepts_new = already_intervened_concepts.clone()\n",
    "#     intervened_concepts_new[range(B), concepts_to_intervene] = 1\n",
    "\n",
    "#     # Temporarily lock other concepts in the same cluster\n",
    "#     for b in range(B):\n",
    "#         selected_concept = concepts_to_intervene[b].item()\n",
    "#         cluster_id = concept_to_cluster[selected_concept]\n",
    "#         cluster_concepts = [c for c in range(k) if concept_to_cluster[c] == cluster_id and c != selected_concept]\n",
    "#         if cluster_concepts:\n",
    "#             intervened_concepts_new[b, cluster_concepts] = 2  # Temporarily locked\n",
    "\n",
    "#     return concepts_new, intervened_concepts_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMConceptCorrector WITH 3-STATE MASK\n",
    "\n",
    "\n",
    "class LSTMConceptCorrector(nn.Module):\n",
    "    \"\"\"\n",
    "    An LSTM-based model that realigns concept vectors based on interventions.\n",
    "\n",
    "    Mask values:\n",
    "        0 => open (LSTM can adjust this concept)\n",
    "        1 => permanently locked to ground truth (once intervened) -> entered ground truth value\n",
    "        2 => temporarily locked (cannot be changed in the current round) -> for concepts outside of intervention cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the LSTMConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features (concepts).\n",
    "            hidden_size (int): Number of features in the hidden state of the LSTM.\n",
    "            num_layers (int): Number of recurrent layers in the LSTM.\n",
    "            output_size (int): Number of output features (concepts).\n",
    "        \"\"\"\n",
    "        super(LSTMConceptCorrector, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define a fully connected layer to map LSTM outputs to concept space\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def prepare_initial_hidden(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Prepares the initial hidden and cell states for the LSTM.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples in the batch.\n",
    "            device (torch.device): Device to place the hidden states.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (h0, c0) initial hidden and cell states.\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the LSTMConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, T, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, T, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, T, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the LSTM.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, T, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Define which concepts are open, permanently locked, and temporarily locked\n",
    "        mask_open = (mask == 0).float()          # 1.0 where open, 0.0 otherwise\n",
    "        mask_perma_locked = (mask == 1).float()  # 1.0 where permanently locked\n",
    "        mask_temp_locked = (mask == 2).float()   # 1.0 where temporarily locked\n",
    "\n",
    "        # Create input for LSTM:\n",
    "        # - For permanently locked concepts (mask=1) and temporarily locked (mask=2), use the current inputs (ground truth).\n",
    "        # - For open concepts (mask=0), use the estimated predictions.\n",
    "        x = mask_perma_locked* inputs * 0 + mask_temp_locked * inputs * 0 +  mask_open * estimated_concepts  # Shape: (B, T, k)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        lstm_out, hidden = self.lstm(x, hidden)  # lstm_out: (B, T, hidden_size)\n",
    "\n",
    "        # Map LSTM outputs to concept space and apply sigmoid activation\n",
    "        corrected_raw = torch.sigmoid(self.fc(lstm_out))  # Shape: (B, T, k)\n",
    "\n",
    "        # Combine corrected concepts with locked and temporarily locked concepts:\n",
    "        # - Keep permanently locked concepts as-is\n",
    "        # - Keep temporarily locked concepts as estimated predictions\n",
    "        # - Update open concepts with the LSTM's corrections\n",
    "        output = mask_perma_locked * inputs + mask_temp_locked * inputs + mask_open * corrected_raw  # Shape: (B, T, k)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def forward_single_timestep(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass for a single time step.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the LSTM.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Add a time dimension of 1 to match the LSTM's expected input shape\n",
    "        inputs_ = inputs.unsqueeze(1)          # Shape: (B, 1, k)\n",
    "        mask_ = mask.unsqueeze(1)              # Shape: (B, 1, k)\n",
    "        est_ = estimated_concepts.unsqueeze(1) # Shape: (B, 1, k)\n",
    "\n",
    "        # Forward pass through the LSTMConceptCorrector\n",
    "        out, hidden = self.forward(inputs_, mask_, est_, hidden)  # out: (B, 1, k)\n",
    "\n",
    "        # Remove the time dimension\n",
    "        out = out.squeeze(1)  # Shape: (B, k)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNConceptCorrector WITH 3-STATE MASK\n",
    "\n",
    "\n",
    "class RNNConceptCorrector(nn.Module):\n",
    "    \"\"\"\n",
    "    An RNN-based model that realigns concept vectors based on interventions.\n",
    "\n",
    "    Mask values:\n",
    "        0 => open (RNN can adjust this concept)\n",
    "        1 => permanently locked to ground truth (once intervened) -> entered ground truth value\n",
    "        2 => temporarily locked (cannot be changed in the current round) -> for concepts outside of intervention cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the RNNConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features (concepts).\n",
    "            hidden_size (int): Number of features in the hidden state of the RNN.\n",
    "            num_layers (int): Number of recurrent layers in the RNN.\n",
    "            output_size (int): Number of output features (concepts).\n",
    "        \"\"\"\n",
    "        super(RNNConceptCorrector, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define a fully connected layer to map RNN outputs to concept space\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def prepare_initial_hidden(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Prepares the initial hidden and cell states for the RNN.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples in the batch.\n",
    "            device (torch.device): Device to place the hidden states.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (h0, c0) initial hidden and cell states.\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the RNNConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, T, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, T, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, T, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the RNN.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, T, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Define which concepts are open, permanently locked, and temporarily locked\n",
    "        mask_open = (mask == 0).float()          # 1.0 where open, 0.0 otherwise\n",
    "        mask_perma_locked = (mask == 1).float()  # 1.0 where permanently locked\n",
    "        mask_temp_locked = (mask == 2).float()   # 1.0 where temporarily locked\n",
    "\n",
    "        # Create input for RNN:\n",
    "        # - For permanently locked concepts (mask=1) and temporarily locked (mask=2), use the current inputs (ground truth).\n",
    "        # - For open concepts (mask=0), use the estimated predictions.\n",
    "        x = mask_perma_locked* inputs * 0 + mask_temp_locked * 0.5 * inputs * 0 +  mask_open * estimated_concepts  # Shape: (B, T, k)\n",
    "\n",
    "        # Pass through RNN\n",
    "        rnn_out, hidden = self.rnn(x, hidden)  # lstm_out: (B, T, hidden_size)\n",
    "\n",
    "        # Map rnn outputs to concept space and apply sigmoid activation\n",
    "        corrected_raw = torch.sigmoid(self.fc(rnn_out))  # Shape: (B, T, k)\n",
    "\n",
    "        # Combine corrected concepts with locked and temporarily locked concepts:\n",
    "        # - Keep permanently locked concepts as-is\n",
    "        # - Keep temporarily locked concepts as estimated predictions\n",
    "        # - Update open concepts with the rnn's corrections\n",
    "        output = mask_perma_locked * inputs + mask_temp_locked * 0.5 * inputs + mask_open * corrected_raw  # Shape: (B, T, k)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def forward_single_timestep(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass for a single time step.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the LSTM.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Add a time dimension of 1 to match the rnn's expected input shape\n",
    "        inputs_ = inputs.unsqueeze(1)          # Shape: (B, 1, k)\n",
    "        mask_ = mask.unsqueeze(1)              # Shape: (B, 1, k)\n",
    "        est_ = estimated_concepts.unsqueeze(1) # Shape: (B, 1, k)\n",
    "\n",
    "        # Forward pass through the rnnConceptCorrector\n",
    "        out, hidden = self.forward(inputs_, mask_, est_, hidden)  # out: (B, 1, k)\n",
    "\n",
    "        # Remove the time dimension\n",
    "        out = out.squeeze(1)  # Shape: (B, k)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRUConceptCorrector WITH 3-STATE MASK\n",
    "\n",
    "\n",
    "class GRUConceptCorrector(nn.Module):\n",
    "    \"\"\"\n",
    "    An GRU-based model that realigns concept vectors based on interventions.\n",
    "\n",
    "    Mask values:\n",
    "        0 => open (GRU can adjust this concept)\n",
    "        1 => permanently locked to ground truth (once intervened) -> entered ground truth value\n",
    "        2 => temporarily locked (cannot be changed in the current round) -> for concepts outside of intervention cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the GRUConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features (concepts).\n",
    "            hidden_size (int): Number of features in the hidden state of the GRU.\n",
    "            num_layers (int): Number of recurrent layers in the GRU.\n",
    "            output_size (int): Number of output features (concepts).\n",
    "        \"\"\"\n",
    "        super(GRUConceptCorrector, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the GRU layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define a fully connected layer to map GRU outputs to concept space\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def prepare_initial_hidden(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Prepares the initial hidden and cell states for the GRU.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples in the batch.\n",
    "            device (torch.device): Device to place the hidden states.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (h0, c0) initial hidden and cell states.\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the GRUConceptCorrector.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, T, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, T, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, T, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the GRU.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, T, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Define which concepts are open, permanently locked, and temporarily locked\n",
    "        mask_open = (mask == 0).float()          # 1.0 where open, 0.0 otherwise\n",
    "        mask_perma_locked = (mask == 1).float()  # 1.0 where permanently locked\n",
    "        mask_temp_locked = (mask == 2).float()   # 1.0 where temporarily locked\n",
    "\n",
    "        # Create input for GRU:\n",
    "        # - For permanently locked concepts (mask=1) and temporarily locked (mask=2), use the current inputs (ground truth).\n",
    "        # - For open concepts (mask=0), use the estimated predictions.\n",
    "        x = mask_perma_locked* inputs * 0 + mask_temp_locked * 0.5 * inputs * 0 +  mask_open * estimated_concepts  # Shape: (B, T, k)\n",
    "\n",
    "        # Pass through GRU\n",
    "        gru_out, hidden = self.gru(x, hidden)  # gru_out: (B, T, hidden_size)\n",
    "\n",
    "        # Map GRU outputs to concept space and apply sigmoid activation\n",
    "        corrected_raw = torch.sigmoid(self.fc(lstm_out))  # Shape: (B, T, k)\n",
    "\n",
    "        # Combine corrected concepts with locked and temporarily locked concepts:\n",
    "        # - Keep permanently locked concepts as-is\n",
    "        # - Keep temporarily locked concepts as estimated predictions\n",
    "        # - Update open concepts with the GRU's corrections\n",
    "        output = mask_perma_locked * inputs + mask_temp_locked * 0.5 * inputs + mask_open * corrected_raw  # Shape: (B, T, k)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def forward_single_timestep(self, inputs, mask, estimated_concepts, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass for a single time step.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Current concept values, shape (B, k).\n",
    "            mask (torch.Tensor): Mask indicating interventions, shape (B, k).\n",
    "                                 0 => open, 1 => permanently locked, 2 => temporarily locked.\n",
    "            estimated_concepts (torch.Tensor): Estimated concept predictions, shape (B, k).\n",
    "            hidden (tuple): Initial hidden and cell states for the LSTM.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated concept values after realignment, shape (B, k).\n",
    "            tuple: Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Add a time dimension of 1 to match the rnn's expected input shape\n",
    "        inputs_ = inputs.unsqueeze(1)          # Shape: (B, 1, k)\n",
    "        mask_ = mask.unsqueeze(1)              # Shape: (B, 1, k)\n",
    "        est_ = estimated_concepts.unsqueeze(1) # Shape: (B, 1, k)\n",
    "\n",
    "        # Forward pass through the rnnConceptCorrector\n",
    "        out, hidden = self.forward(inputs_, mask_, est_, hidden)  # out: (B, 1, k)\n",
    "\n",
    "        # Remove the time dimension\n",
    "        out = out.squeeze(1)  # Shape: (B, k)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE TRAJECTORY FUNCTION\n",
    "\n",
    "\n",
    "def sample_trajectory(model, predicted_concepts, groundtruth_concepts, \n",
    "                     concept_to_cluster, max_interventions=3, intervention_policy=ucp):\n",
    "    \"\"\"\n",
    "    Simulates multiple rounds of interventions and realignments.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The concept corrector model.\n",
    "        predicted_concepts (torch.Tensor): Predicted concepts, shape (B, k).\n",
    "        groundtruth_concepts (torch.Tensor): Ground truth concepts, shape (B, k).\n",
    "        concept_to_cluster (list): List mapping each concept to its cluster, length k.\n",
    "        max_interventions (int): Number of intervention steps to perform.\n",
    "        intervention_policy (function): Function to compute importances.\n",
    "\n",
    "    Returns:\n",
    "        list of torch.Tensor: Concept vectors at each intervention step, length (max_interventions + 1),\n",
    "                              each tensor of shape (B, k).\n",
    "    \"\"\"\n",
    "    device = predicted_concepts.device\n",
    "    B, k = predicted_concepts.shape\n",
    "\n",
    "    # Initialize masks: 1 => permanently locked, 0 => open, 2 => temporarily locked\n",
    "    already_intervened_concepts = torch.zeros(B, k).to(device)\n",
    "\n",
    "    # Clone predicted concepts to start\n",
    "    current_concepts = predicted_concepts.clone()\n",
    "\n",
    "    # Prepare initial hidden state\n",
    "    hidden = model.prepare_initial_hidden(B, device)\n",
    "\n",
    "    # Store all steps for analysis\n",
    "    all_steps = [current_concepts.clone()]\n",
    "\n",
    "    for step in range(max_interventions):\n",
    "        # Apply intervention\n",
    "        concepts_new, intervened_concepts_new = intervene(\n",
    "            concepts=current_concepts,\n",
    "            concept_to_cluster=concept_to_cluster,\n",
    "            already_intervened_concepts=already_intervened_concepts,\n",
    "            groundtruth_concepts=groundtruth_concepts,\n",
    "            intervention_policy=intervention_policy\n",
    "        )\n",
    "\n",
    "        # Update concepts and masks\n",
    "        current_concepts = concepts_new\n",
    "        already_intervened_concepts = intervened_concepts_new\n",
    "\n",
    "        # Realign with the model\n",
    "        corrected_concepts, hidden = model.forward_single_timestep(\n",
    "            inputs=current_concepts,\n",
    "            mask=already_intervened_concepts.float(),  # Convert mask to float for the model\n",
    "            estimated_concepts=predicted_concepts,\n",
    "            hidden=hidden\n",
    "        )\n",
    "\n",
    "        # Update current concepts with corrected values\n",
    "        current_concepts = corrected_concepts\n",
    "\n",
    "        # Reset temporary locks (mask=2) back to open (mask=0)\n",
    "        already_intervened_concepts = torch.where(already_intervened_concepts == 2, \n",
    "                                                 torch.zeros_like(already_intervened_concepts), \n",
    "                                                 already_intervened_concepts)\n",
    "\n",
    "        # Store the step\n",
    "        all_steps.append(current_concepts.clone())\n",
    "\n",
    "    return all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # hyperpar synthetic data\n",
    "    k = 6           # Number of concepts\n",
    "    n = 100         # Number of observations\n",
    "    J = 3           # Number of target classes\n",
    "    m = 2           # Number of concept clusters\n",
    "    seed = 42       # Random seed for reproducibility\n",
    "\n",
    "    # Generate synthetic data\n",
    "    predicted_concepts, groundtruth_concepts, cluster_assignments, labels = generate_synthetic_data(\n",
    "        k=k,\n",
    "        n=n,\n",
    "        J=J,\n",
    "        m=m,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Print Cluster Assignments for Reference\n",
    "    print(\"=== Cluster Assignments ===\")\n",
    "    for cid, c_list in cluster_assignments.items():\n",
    "        print(f\"Cluster {cid}: {c_list}\")\n",
    "    print()\n",
    "\n",
    "    # Prepare concept_to_cluster list\n",
    "    concept_to_cluster = [0] * k  # Initialize list\n",
    "    for cid, c_list in cluster_assignments.items():\n",
    "        for c in c_list:\n",
    "            concept_to_cluster[c] = cid\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = TensorDataset(predicted_concepts, groundtruth_concepts, labels)\n",
    "    batch_size = 16\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize the LSTMConceptCorrector model\n",
    "    hidden_size = 16\n",
    "    num_layers = 1\n",
    "    output_size = k  # Same as number of concepts\n",
    "    model = GRUConceptCorrector(input_size=k, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "    device = torch.device(\"cpu\")  # Change to \"cuda\" if GPU is available\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Move data to device\n",
    "    predicted_concepts = predicted_concepts.to(device)\n",
    "    groundtruth_concepts = groundtruth_concepts.to(device)\n",
    "\n",
    "    # Define loss criterion and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training hyperparameters\n",
    "    epochs = 100\n",
    "    max_interventions = 5  # Number of intervention steps per batch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, (pred_c, gt_c, lbls) in enumerate(dataloader):\n",
    "            # Move batch data to device\n",
    "            pred_c = pred_c.to(device)  # Shape: (B, k)\n",
    "            gt_c = gt_c.to(device)      # Shape: (B, k)\n",
    "            lbls = lbls.to(device)      # Shape: (B,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform multiple intervention steps and realignments\n",
    "            all_steps = sample_trajectory(\n",
    "                model=model,\n",
    "                predicted_concepts=pred_c,\n",
    "                groundtruth_concepts=gt_c,\n",
    "                concept_to_cluster=concept_to_cluster,\n",
    "                max_interventions=max_interventions,\n",
    "                intervention_policy=ucp\n",
    "            )\n",
    "\n",
    "            # Use the final corrected concepts for loss computation\n",
    "            final_corrected_concepts = all_steps[-1]  # Shape: (B, k)\n",
    "\n",
    "            # Compute loss against ground truth concepts\n",
    "            loss = criterion(final_corrected_concepts, gt_c)\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Compute average loss for the epoch\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "\n",
    "    # (Optional) Inspect final cluster assignments and model predictions\n",
    "    print(\"\\n=== Final Cluster Assignments ===\")\n",
    "    for cid, c_list in cluster_assignments.items():\n",
    "        print(f\"Cluster {cid}: {c_list}\")\n",
    "\n",
    "    # (Optional) Print some example corrected concepts\n",
    "    print(\"\\n=== Example Corrected Concepts ===\")\n",
    "    example_steps = sample_trajectory(\n",
    "        model=model,\n",
    "        predicted_concepts=predicted_concepts[:5],      # Take first 5 samples\n",
    "        groundtruth_concepts=groundtruth_concepts[:5],\n",
    "        concept_to_cluster=concept_to_cluster,\n",
    "        max_interventions=max_interventions,\n",
    "        intervention_policy=ucp\n",
    "    )\n",
    "\n",
    "    for step_idx, cvec in enumerate(example_steps):\n",
    "        print(f\"Step {step_idx}:\")\n",
    "        print(cvec)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cluster Assignments ===\n",
      "Cluster 0: [0, 4]\n",
      "Cluster 1: [1, 2, 3, 5]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# RUN MAIN FUNCTION\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 72\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Perform multiple intervention steps and realignments\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m all_steps \u001b[38;5;241m=\u001b[39m \u001b[43msample_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredicted_concepts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroundtruth_concepts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcept_to_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcept_to_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_interventions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_interventions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervention_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mucp\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Use the final corrected concepts for loss computation\u001b[39;00m\n\u001b[0;32m     82\u001b[0m final_corrected_concepts \u001b[38;5;241m=\u001b[39m all_steps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Shape: (B, k)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 51\u001b[0m, in \u001b[0;36msample_trajectory\u001b[1;34m(model, predicted_concepts, groundtruth_concepts, concept_to_cluster, max_interventions, intervention_policy)\u001b[0m\n\u001b[0;32m     48\u001b[0m already_intervened_concepts \u001b[38;5;241m=\u001b[39m intervened_concepts_new\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Realign with the model\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m corrected_concepts, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_timestep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_concepts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malready_intervened_concepts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert mask to float for the model\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimated_concepts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted_concepts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Update current concepts with corrected values\u001b[39;00m\n\u001b[0;32m     59\u001b[0m current_concepts \u001b[38;5;241m=\u001b[39m corrected_concepts\n",
      "Cell \u001b[1;32mIn[28], line 109\u001b[0m, in \u001b[0;36mGRUConceptCorrector.forward_single_timestep\u001b[1;34m(self, inputs, mask, estimated_concepts, hidden)\u001b[0m\n\u001b[0;32m    106\u001b[0m est_ \u001b[38;5;241m=\u001b[39m estimated_concepts\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Shape: (B, 1, k)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Forward pass through the rnnConceptCorrector\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: (B, 1, k)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Remove the time dimension\u001b[39;00m\n\u001b[0;32m    112\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (B, k)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 75\u001b[0m, in \u001b[0;36mGRUConceptCorrector.forward\u001b[1;34m(self, inputs, mask, estimated_concepts, hidden)\u001b[0m\n\u001b[0;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m mask_perma_locked\u001b[38;5;241m*\u001b[39m inputs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m mask_temp_locked \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m inputs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m  mask_open \u001b[38;5;241m*\u001b[39m estimated_concepts  \u001b[38;5;66;03m# Shape: (B, T, k)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Pass through GRU\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m gru_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# gru_out: (B, T, hidden_size)\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Map GRU outputs to concept space and apply sigmoid activation\u001b[39;00m\n\u001b[0;32m     78\u001b[0m corrected_raw \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out))  \u001b[38;5;66;03m# Shape: (B, T, k)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sari_\\anaconda3\\envs\\ReTAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sari_\\anaconda3\\envs\\ReTAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sari_\\anaconda3\\envs\\ReTAI\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1121\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mhx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx should also be 3-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1124\u001b[0m max_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# RUN MAIN FUNCTION\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReTAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
